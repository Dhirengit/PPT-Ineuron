{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.009468Z",
     "iopub.status.busy": "2023-08-26T07:13:14.009064Z",
     "iopub.status.idle": "2023-08-26T07:13:14.022200Z",
     "shell.execute_reply": "2023-08-26T07:13:14.021110Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.009418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import copy\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import euclidean, jaccard, hamming\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, classification_report"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q-1. Imagine you have a dataset where you have different Instagram features\n",
    "like username, Caption, Hashtag, Followers, Time_Since_posted, and likes, now your task is\n",
    "to predict the number of likes and Time Since posted and the rest of the features are\n",
    "your input features. Now you have to build a model which can predict the\n",
    "number of likes and Time Since posted.\n",
    "Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.025707Z",
     "iopub.status.busy": "2023-08-26T07:13:14.025022Z",
     "iopub.status.idle": "2023-08-26T07:13:14.280246Z",
     "shell.execute_reply": "2023-08-26T07:13:14.279322Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.025671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>onthetopsearch</td>\n",
       "      <td>“No one buys things from Facebook.” “Instagram...</td>\n",
       "      <td>1041</td>\n",
       "      <td>#digitalmarketing #machinelearning#entrepreneu...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  S.No        USERNAME  \\\n",
       "22          22    26  onthetopsearch   \n",
       "\n",
       "                                              Caption  Followers  \\\n",
       "22  “No one buys things from Facebook.” “Instagram...       1041   \n",
       "\n",
       "                                             Hashtags Time since posted  Likes  \n",
       "22  #digitalmarketing #machinelearning#entrepreneu...           2 hours     20  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = pd.read_csv(\"Datasets/instagram_reach.csv\")\n",
    "df1 = pd.read_csv(\"https://raw.githubusercontent.com/Dhirengit/PPT-Ineuron/main/DataSets/instagram_reach.csv\")\n",
    "df1.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.282190Z",
     "iopub.status.busy": "2023-08-26T07:13:14.281852Z",
     "iopub.status.idle": "2023-08-26T07:13:14.289307Z",
     "shell.execute_reply": "2023-08-26T07:13:14.288414Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.282158Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True)\n",
    "df1[\"Time\"] = df1[\"Time since posted\"].apply(lambda x: int(x.split(\" \")[0]))\n",
    "df1.drop(columns=[\"Unnamed: 0\",\"S.No\", \"Caption\", \"USERNAME\",\"Time since posted\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.941645Z",
     "iopub.status.busy": "2023-08-26T07:13:14.940648Z",
     "iopub.status.idle": "2023-08-26T07:13:14.954744Z",
     "shell.execute_reply": "2023-08-26T07:13:14.953585Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.941609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Followers  100 non-null    int64 \n",
      " 1   Hashtags   100 non-null    object\n",
      " 2   Likes      100 non-null    int64 \n",
      " 3   Time       100 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.957721Z",
     "iopub.status.busy": "2023-08-26T07:13:14.957252Z",
     "iopub.status.idle": "2023-08-26T07:13:14.978569Z",
     "shell.execute_reply": "2023-08-26T07:13:14.977572Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.957686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>961.96000</td>\n",
       "      <td>46.48000</td>\n",
       "      <td>3.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1014.62567</td>\n",
       "      <td>55.08698</td>\n",
       "      <td>3.394648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>252.75000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>612.00000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1197.00000</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4496.00000</td>\n",
       "      <td>349.00000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Followers      Likes        Time\n",
       "count   100.00000  100.00000  100.000000\n",
       "mean    961.96000   46.48000    3.460000\n",
       "std    1014.62567   55.08698    3.394648\n",
       "min      11.00000    8.00000    2.000000\n",
       "25%     252.75000   19.00000    2.000000\n",
       "50%     612.00000   29.00000    2.000000\n",
       "75%    1197.00000   46.00000    3.000000\n",
       "max    4496.00000  349.00000   24.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.980388Z",
     "iopub.status.busy": "2023-08-26T07:13:14.980026Z",
     "iopub.status.idle": "2023-08-26T07:13:14.986265Z",
     "shell.execute_reply": "2023-08-26T07:13:14.985322Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.980353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    #MachineLearning #AI #DataAnalytics #DataScien...\n",
      "Name: Hashtags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df1.loc[:0][\"Hashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:14.988619Z",
     "iopub.status.busy": "2023-08-26T07:13:14.987867Z",
     "iopub.status.idle": "2023-08-26T07:13:14.999967Z",
     "shell.execute_reply": "2023-08-26T07:13:14.998968Z",
     "shell.execute_reply.started": "2023-08-26T07:13:14.988561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machinelearning', 'ai', 'dataanalytics', 'datascienc', 'datalake']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_hastag(text):\n",
    "    ps = PorterStemmer()\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    \n",
    "    tags = nltk.sent_tokenize(text)\n",
    "    corpus = []\n",
    "    tag = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tag = tag.lower()\n",
    "    tag = tag.split()\n",
    "#     tag = [wordnet.lemmatize(word) for word in tag if not word in set(stopwords.words(\"english\"))]\n",
    "    \n",
    "    return tag\n",
    "\n",
    "convert_hastag(df1[\"Hashtags\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.003723Z",
     "iopub.status.busy": "2023-08-26T07:13:15.003411Z",
     "iopub.status.idle": "2023-08-26T07:13:15.024979Z",
     "shell.execute_reply": "2023-08-26T07:13:15.023864Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.003699Z"
    }
   },
   "outputs": [],
   "source": [
    "hastag = pd.DataFrame()\n",
    "df1[\"Hashtags\"]= df1[\"Hashtags\"].apply(convert_hastag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.028704Z",
     "iopub.status.busy": "2023-08-26T07:13:15.028295Z",
     "iopub.status.idle": "2023-08-26T07:13:15.040843Z",
     "shell.execute_reply": "2023-08-26T07:13:15.039565Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.028679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Hashtags\n",
      "0   [machinelearning, ai, dataanalytics, datascien...\n",
      "1   [deck, mac, macintosh, sayhello, apple, stevej...\n",
      "2   [whoiswho, aitrading, ai, aitradingteam, insta...\n",
      "3   [iot, cre, workplace, cdo, bigdata, technology...\n",
      "4   [instamachinelearning, instabigdata, instamark...\n",
      "..                                                ...\n",
      "95  [beverlyhills, realestate, losangelesrealestat...\n",
      "96  [workspace, work, developer, development, deve...\n",
      "97  [books, book, motivation, inspiration, life, b...\n",
      "98  [heavyequipment, underconstruction, dozer, rea...\n",
      "99  [marketing, programming, development, desarrol...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1[[\"Hashtags\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.043082Z",
     "iopub.status.busy": "2023-08-26T07:13:15.042139Z",
     "iopub.status.idle": "2023-08-26T07:13:15.053042Z",
     "shell.execute_reply": "2023-08-26T07:13:15.052030Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.043049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1155"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hashtag = set(tag for row in df1[\"Hashtags\"] for tag in row)\n",
    "len(unique_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.055912Z",
     "iopub.status.busy": "2023-08-26T07:13:15.055574Z",
     "iopub.status.idle": "2023-08-26T07:13:15.565769Z",
     "shell.execute_reply": "2023-08-26T07:13:15.564845Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.055881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n",
      "/tmp/ipykernel_28/1276266570.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[hashtag] = 0 # initialize 0 value for every hashtag\n"
     ]
    }
   ],
   "source": [
    "for hashtag in unique_hashtag:\n",
    "    df1[hashtag] = 0 # initialize 0 value for every hashtag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.568293Z",
     "iopub.status.busy": "2023-08-26T07:13:15.567361Z",
     "iopub.status.idle": "2023-08-26T07:13:15.628528Z",
     "shell.execute_reply": "2023-08-26T07:13:15.627574Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.568258Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, row in enumerate(df1[\"Hashtags\"]): # enumerate hashtags \n",
    "    for tag in row: # Row wise hashtag \n",
    "        df1.at[index, tag] = 1 # appply 1 value when index and tag match \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.630254Z",
     "iopub.status.busy": "2023-08-26T07:13:15.629932Z",
     "iopub.status.idle": "2023-08-26T07:13:15.673795Z",
     "shell.execute_reply": "2023-08-26T07:13:15.672961Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.630223Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=[\"Hashtags\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.675934Z",
     "iopub.status.busy": "2023-08-26T07:13:15.675376Z",
     "iopub.status.idle": "2023-08-26T07:13:15.714617Z",
     "shell.execute_reply": "2023-08-26T07:13:15.713758Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.675900Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = df1.drop(columns=[\"Likes\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.718305Z",
     "iopub.status.busy": "2023-08-26T07:13:15.718038Z",
     "iopub.status.idle": "2023-08-26T07:13:15.738497Z",
     "shell.execute_reply": "2023-08-26T07:13:15.737512Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.718281Z"
    }
   },
   "outputs": [],
   "source": [
    "y1 = df1[[\"Likes\", \"Time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.741149Z",
     "iopub.status.busy": "2023-08-26T07:13:15.740587Z",
     "iopub.status.idle": "2023-08-26T07:13:15.762542Z",
     "shell.execute_reply": "2023-08-26T07:13:15.761673Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.741116Z"
    }
   },
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.765850Z",
     "iopub.status.busy": "2023-08-26T07:13:15.765584Z",
     "iopub.status.idle": "2023-08-26T07:13:15.773680Z",
     "shell.execute_reply": "2023-08-26T07:13:15.772782Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.765827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (90, 1156)\n",
      "X_test shape = (10, 1156)\n",
      "y_train shape = (90, 2)\n",
      "y_test shape = (10, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape = {x1_train.shape}\")\n",
    "print(f\"X_test shape = {x1_test.shape}\")\n",
    "print(f\"y_train shape = {y1_train.shape}\")\n",
    "print(f\"y_test shape = {y1_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.776872Z",
     "iopub.status.busy": "2023-08-26T07:13:15.776303Z",
     "iopub.status.idle": "2023-08-26T07:13:15.789547Z",
     "shell.execute_reply": "2023-08-26T07:13:15.788493Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.776840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Likes</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Likes  Time\n",
       "97     10     3\n",
       "72     20     2\n",
       "70     21     2\n",
       "34    273     2\n",
       "46     24     2\n",
       "47     51     3\n",
       "86     43     4\n",
       "79     29     2\n",
       "40     24     2\n",
       "0     139    11"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:15.792847Z",
     "iopub.status.busy": "2023-08-26T07:13:15.792487Z",
     "iopub.status.idle": "2023-08-26T07:13:15.798638Z",
     "shell.execute_reply": "2023-08-26T07:13:15.797372Z",
     "shell.execute_reply.started": "2023-08-26T07:13:15.792822Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.216948Z",
     "iopub.status.busy": "2023-08-26T07:13:16.216299Z",
     "iopub.status.idle": "2023-08-26T07:13:16.821218Z",
     "shell.execute_reply": "2023-08-26T07:13:16.820263Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.216907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.824834Z",
     "iopub.status.busy": "2023-08-26T07:13:16.824059Z",
     "iopub.status.idle": "2023-08-26T07:13:16.852576Z",
     "shell.execute_reply": "2023-08-26T07:13:16.851421Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.824803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16.17      ,   2.18      ],\n",
       "       [ 31.36      ,   2.43      ],\n",
       "       [ 26.17      ,   2.39      ],\n",
       "       [ 16.13      ,   2.13      ],\n",
       "       [ 44.82      ,   3.9       ],\n",
       "       [109.01      ,   4.14      ],\n",
       "       [ 35.65      ,   2.67666667],\n",
       "       [ 33.78      ,   2.69666667],\n",
       "       [ 19.14      ,   2.26      ],\n",
       "       [ 63.11      ,   6.09      ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred = rf.predict(x1_test)\n",
    "y1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.854288Z",
     "iopub.status.busy": "2023-08-26T07:13:16.853960Z",
     "iopub.status.idle": "2023-08-26T07:13:16.862293Z",
     "shell.execute_reply": "2023-08-26T07:13:16.861229Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.854256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3793.340377777778"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse1 = mean_squared_error(y1_test, y1_pred)\n",
    "mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.864538Z",
     "iopub.status.busy": "2023-08-26T07:13:16.863824Z",
     "iopub.status.idle": "2023-08-26T07:13:16.873594Z",
     "shell.execute_reply": "2023-08-26T07:13:16.872566Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.864499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.590099673387265"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse1 = np.sqrt(mse1)\n",
    "rmse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.878090Z",
     "iopub.status.busy": "2023-08-26T07:13:16.877747Z",
     "iopub.status.idle": "2023-08-26T07:13:16.889169Z",
     "shell.execute_reply": "2023-08-26T07:13:16.888210Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.878064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14806848117175264"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2score1 = r2_score(y1_test, y1_pred)\n",
    "r2score1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q-2. Imagine you have a dataset where you have different features like Age ,\n",
    "Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into\n",
    "different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using\n",
    "any 4 different classification algorithms. Now you have to build a model which\n",
    "can classify people into different classes.\n",
    "Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:16.890612Z",
     "iopub.status.busy": "2023-08-26T07:13:16.890266Z",
     "iopub.status.idle": "2023-08-26T07:13:17.143234Z",
     "shell.execute_reply": "2023-08-26T07:13:17.142303Z",
     "shell.execute_reply.started": "2023-08-26T07:13:16.890545Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv(\"DataSets/ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "df2 = pd.read_csv(\"https://raw.githubusercontent.com/Dhirengit/PPT-Ineuron/main/DataSets/ObesityDataSet_raw_and_data_sinthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.146076Z",
     "iopub.status.busy": "2023-08-26T07:13:17.145371Z",
     "iopub.status.idle": "2023-08-26T07:13:17.169290Z",
     "shell.execute_reply": "2023-08-26T07:13:17.168173Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.146043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.171859Z",
     "iopub.status.busy": "2023-08-26T07:13:17.171381Z",
     "iopub.status.idle": "2023-08-26T07:13:17.188291Z",
     "shell.execute_reply": "2023-08-26T07:13:17.187403Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.171826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                            0\n",
       "Age                               0\n",
       "Height                            0\n",
       "Weight                            0\n",
       "family_history_with_overweight    0\n",
       "FAVC                              0\n",
       "FCVC                              0\n",
       "NCP                               0\n",
       "CAEC                              0\n",
       "SMOKE                             0\n",
       "CH2O                              0\n",
       "SCC                               0\n",
       "FAF                               0\n",
       "TUE                               0\n",
       "CALC                              0\n",
       "MTRANS                            0\n",
       "NObeyesdad                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.190541Z",
     "iopub.status.busy": "2023-08-26T07:13:17.189959Z",
     "iopub.status.idle": "2023-08-26T07:13:17.225329Z",
     "shell.execute_reply": "2023-08-26T07:13:17.224209Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.190508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.312600</td>\n",
       "      <td>1.701677</td>\n",
       "      <td>86.586058</td>\n",
       "      <td>2.419043</td>\n",
       "      <td>2.685628</td>\n",
       "      <td>2.008011</td>\n",
       "      <td>1.010298</td>\n",
       "      <td>0.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.345968</td>\n",
       "      <td>0.093305</td>\n",
       "      <td>26.191172</td>\n",
       "      <td>0.533927</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.612953</td>\n",
       "      <td>0.850592</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.947192</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>65.473343</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.658738</td>\n",
       "      <td>1.584812</td>\n",
       "      <td>0.124505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.777890</td>\n",
       "      <td>1.700499</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.385502</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.768464</td>\n",
       "      <td>107.430682</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.477420</td>\n",
       "      <td>1.666678</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Height       Weight         FCVC          NCP  \\\n",
       "count  2111.000000  2111.000000  2111.000000  2111.000000  2111.000000   \n",
       "mean     24.312600     1.701677    86.586058     2.419043     2.685628   \n",
       "std       6.345968     0.093305    26.191172     0.533927     0.778039   \n",
       "min      14.000000     1.450000    39.000000     1.000000     1.000000   \n",
       "25%      19.947192     1.630000    65.473343     2.000000     2.658738   \n",
       "50%      22.777890     1.700499    83.000000     2.385502     3.000000   \n",
       "75%      26.000000     1.768464   107.430682     3.000000     3.000000   \n",
       "max      61.000000     1.980000   173.000000     3.000000     4.000000   \n",
       "\n",
       "              CH2O          FAF          TUE  \n",
       "count  2111.000000  2111.000000  2111.000000  \n",
       "mean      2.008011     1.010298     0.657866  \n",
       "std       0.612953     0.850592     0.608927  \n",
       "min       1.000000     0.000000     0.000000  \n",
       "25%       1.584812     0.124505     0.000000  \n",
       "50%       2.000000     1.000000     0.625350  \n",
       "75%       2.477420     1.666678     1.000000  \n",
       "max       3.000000     3.000000     2.000000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.227393Z",
     "iopub.status.busy": "2023-08-26T07:13:17.227033Z",
     "iopub.status.idle": "2023-08-26T07:13:17.246750Z",
     "shell.execute_reply": "2023-08-26T07:13:17.245787Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.227359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   object \n",
      " 1   Age                             2111 non-null   float64\n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   object \n",
      " 5   FAVC                            2111 non-null   object \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   object \n",
      " 9   SMOKE                           2111 non-null   object \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   object \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   object \n",
      " 15  MTRANS                          2111 non-null   object \n",
      " 16  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 280.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.248464Z",
     "iopub.status.busy": "2023-08-26T07:13:17.248055Z",
     "iopub.status.idle": "2023-08-26T07:13:17.271354Z",
     "shell.execute_reply": "2023-08-26T07:13:17.270362Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.248416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Male</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.022598</td>\n",
       "      <td>1.747739</td>\n",
       "      <td>83.314157</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.011656</td>\n",
       "      <td>3.165837</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.844645</td>\n",
       "      <td>no</td>\n",
       "      <td>0.889963</td>\n",
       "      <td>0.395979</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.654316</td>\n",
       "      <td>1.621233</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.063449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.482016</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height     Weight family_history_with_overweight  \\\n",
       "339   Female  19.000000  1.530000  42.000000                             no   \n",
       "230     Male  20.000000  1.900000  91.000000                            yes   \n",
       "205   Female  23.000000  1.600000  78.000000                            yes   \n",
       "1128    Male  30.022598  1.747739  83.314157                            yes   \n",
       "1217  Female  22.654316  1.621233  82.000000                            yes   \n",
       "\n",
       "     FAVC      FCVC       NCP       CAEC SMOKE      CH2O  SCC       FAF  \\\n",
       "339    no  2.000000  3.000000  Sometimes    no  1.000000  yes  2.000000   \n",
       "230   yes  3.000000  4.000000  Sometimes    no  3.000000   no  2.000000   \n",
       "205   yes  2.000000  1.000000  Sometimes   yes  2.000000   no  1.000000   \n",
       "1128  yes  2.011656  3.165837  Sometimes    no  1.844645   no  0.889963   \n",
       "1217  yes  1.063449  1.000000  Sometimes    no  2.000000   no  0.000000   \n",
       "\n",
       "           TUE        CALC                 MTRANS           NObeyesdad  \n",
       "339   0.000000  Frequently  Public_Transportation  Insufficient_Weight  \n",
       "230   0.000000   Sometimes                Walking   Overweight_Level_I  \n",
       "205   0.000000  Frequently  Public_Transportation       Obesity_Type_I  \n",
       "1128  0.395979          no             Automobile  Overweight_Level_II  \n",
       "1217  1.482016   Sometimes  Public_Transportation       Obesity_Type_I  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.273277Z",
     "iopub.status.busy": "2023-08-26T07:13:17.272688Z",
     "iopub.status.idle": "2023-08-26T07:13:17.279497Z",
     "shell.execute_reply": "2023-08-26T07:13:17.278617Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.273240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"SCC\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.281336Z",
     "iopub.status.busy": "2023-08-26T07:13:17.280640Z",
     "iopub.status.idle": "2023-08-26T07:13:17.291319Z",
     "shell.execute_reply": "2023-08-26T07:13:17.290426Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.281304Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[[\"Age\", \"Weight\"]] = df2[[\"Age\", \"Weight\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.297697Z",
     "iopub.status.busy": "2023-08-26T07:13:17.297090Z",
     "iopub.status.idle": "2023-08-26T07:13:17.304687Z",
     "shell.execute_reply": "2023-08-26T07:13:17.303951Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.297666Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"Gender\"] = df2[\"Gender\"].apply(lambda x : 1 if x == \"Male\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.306790Z",
     "iopub.status.busy": "2023-08-26T07:13:17.305944Z",
     "iopub.status.idle": "2023-08-26T07:13:17.314926Z",
     "shell.execute_reply": "2023-08-26T07:13:17.314243Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.306758Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"SMOKE\"] = df2[\"SMOKE\"].apply(lambda x : 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.316977Z",
     "iopub.status.busy": "2023-08-26T07:13:17.315962Z",
     "iopub.status.idle": "2023-08-26T07:13:17.325234Z",
     "shell.execute_reply": "2023-08-26T07:13:17.324541Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.316945Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"family_history_with_overweight\"] = df2[\"family_history_with_overweight\"].apply(lambda x : 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.327400Z",
     "iopub.status.busy": "2023-08-26T07:13:17.326490Z",
     "iopub.status.idle": "2023-08-26T07:13:17.335343Z",
     "shell.execute_reply": "2023-08-26T07:13:17.334420Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.327368Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"FAVC\"] = df2[\"FAVC\"].apply(lambda x : 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.338284Z",
     "iopub.status.busy": "2023-08-26T07:13:17.338001Z",
     "iopub.status.idle": "2023-08-26T07:13:17.346760Z",
     "shell.execute_reply": "2023-08-26T07:13:17.345910Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.338261Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"SCC\"] = df2[\"SCC\"].apply(lambda x : 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.348929Z",
     "iopub.status.busy": "2023-08-26T07:13:17.348313Z",
     "iopub.status.idle": "2023-08-26T07:13:17.375265Z",
     "shell.execute_reply": "2023-08-26T07:13:17.374369Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.348896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>0</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>0</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>0</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>0</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2111 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age    Height  Weight  family_history_with_overweight  FAVC  \\\n",
       "0          0   21  1.620000      64                               1     0   \n",
       "1          0   21  1.520000      56                               1     0   \n",
       "2          1   23  1.800000      77                               1     0   \n",
       "3          1   27  1.800000      87                               0     0   \n",
       "4          1   22  1.780000      89                               0     0   \n",
       "...      ...  ...       ...     ...                             ...   ...   \n",
       "2106       0   20  1.710730     131                               1     1   \n",
       "2107       0   21  1.748584     133                               1     1   \n",
       "2108       0   22  1.752206     133                               1     1   \n",
       "2109       0   24  1.739450     133                               1     1   \n",
       "2110       0   23  1.738836     133                               1     1   \n",
       "\n",
       "      FCVC  NCP       CAEC  SMOKE      CH2O  SCC       FAF       TUE  \\\n",
       "0      2.0  3.0  Sometimes      0  2.000000    0  0.000000  1.000000   \n",
       "1      3.0  3.0  Sometimes      1  3.000000    1  3.000000  0.000000   \n",
       "2      2.0  3.0  Sometimes      0  2.000000    0  2.000000  1.000000   \n",
       "3      3.0  3.0  Sometimes      0  2.000000    0  2.000000  0.000000   \n",
       "4      2.0  1.0  Sometimes      0  2.000000    0  0.000000  0.000000   \n",
       "...    ...  ...        ...    ...       ...  ...       ...       ...   \n",
       "2106   3.0  3.0  Sometimes      0  1.728139    0  1.676269  0.906247   \n",
       "2107   3.0  3.0  Sometimes      0  2.005130    0  1.341390  0.599270   \n",
       "2108   3.0  3.0  Sometimes      0  2.054193    0  1.414209  0.646288   \n",
       "2109   3.0  3.0  Sometimes      0  2.852339    0  1.139107  0.586035   \n",
       "2110   3.0  3.0  Sometimes      0  2.863513    0  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS           NObeyesdad  \n",
       "0             no  Public_Transportation        Normal_Weight  \n",
       "1      Sometimes  Public_Transportation        Normal_Weight  \n",
       "2     Frequently  Public_Transportation        Normal_Weight  \n",
       "3     Frequently                Walking   Overweight_Level_I  \n",
       "4      Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "...          ...                    ...                  ...  \n",
       "2106   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2107   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2108   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2109   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "2110   Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "\n",
       "[2111 rows x 17 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.378081Z",
     "iopub.status.busy": "2023-08-26T07:13:17.377519Z",
     "iopub.status.idle": "2023-08-26T07:13:17.386165Z",
     "shell.execute_reply": "2023-08-26T07:13:17.385092Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.378048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Public_Transportation', 'Walking', 'Automobile', 'Motorbike',\n",
       "       'Bike'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"MTRANS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.387476Z",
     "iopub.status.busy": "2023-08-26T07:13:17.387201Z",
     "iopub.status.idle": "2023-08-26T07:13:17.393263Z",
     "shell.execute_reply": "2023-08-26T07:13:17.392116Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.387427Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.395527Z",
     "iopub.status.busy": "2023-08-26T07:13:17.394653Z",
     "iopub.status.idle": "2023-08-26T07:13:17.403060Z",
     "shell.execute_reply": "2023-08-26T07:13:17.402121Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.395496Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"CAEC\"] =label_encoder.fit_transform(df2[\"CAEC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.404868Z",
     "iopub.status.busy": "2023-08-26T07:13:17.404379Z",
     "iopub.status.idle": "2023-08-26T07:13:17.413348Z",
     "shell.execute_reply": "2023-08-26T07:13:17.412720Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.404837Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"CALC\"] = label_encoder.fit_transform(df2[\"CALC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.415431Z",
     "iopub.status.busy": "2023-08-26T07:13:17.414683Z",
     "iopub.status.idle": "2023-08-26T07:13:17.424182Z",
     "shell.execute_reply": "2023-08-26T07:13:17.423549Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.415397Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"MTRANS\"] = label_encoder.fit_transform(df2[\"MTRANS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.427359Z",
     "iopub.status.busy": "2023-08-26T07:13:17.426680Z",
     "iopub.status.idle": "2023-08-26T07:13:17.433875Z",
     "shell.execute_reply": "2023-08-26T07:13:17.433190Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.427328Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"NObeyesdad\"] = label_encoder.fit_transform(df2[\"NObeyesdad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.435948Z",
     "iopub.status.busy": "2023-08-26T07:13:17.435239Z",
     "iopub.status.idle": "2023-08-26T07:13:17.458328Z",
     "shell.execute_reply": "2023-08-26T07:13:17.457274Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.435914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.753389</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.166450</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.278578</td>\n",
       "      <td>0</td>\n",
       "      <td>1.838881</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.751691</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.478891</td>\n",
       "      <td>3.371832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.004126</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.327376</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1.676595</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.934671</td>\n",
       "      <td>2.119682</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.041462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1.762921</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.136830</td>\n",
       "      <td>2.993084</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.885926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age    Height  Weight  family_history_with_overweight  FAVC  \\\n",
       "607        1   18  1.753389      54                               1     1   \n",
       "629        0   22  1.751691      55                               1     1   \n",
       "1312       1   31  1.676595      89                               1     1   \n",
       "1775       1   37  1.762921     118                               1     1   \n",
       "69         1   23  1.800000      60                               1     0   \n",
       "\n",
       "          FCVC       NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  \\\n",
       "607   2.000000  3.166450     2      0  2.278578    0  1.838881  2.000000   \n",
       "629   2.478891  3.371832     1      0  2.004126    0  2.000000  0.327376   \n",
       "1312  2.934671  2.119682     2      0  2.041462    0  0.578074  0.000000   \n",
       "1775  2.136830  2.993084     2      0  1.885926    0  0.615298  0.000000   \n",
       "69    2.000000  3.000000     3      0  3.000000    0  0.000000  1.000000   \n",
       "\n",
       "      CALC  MTRANS  NObeyesdad  \n",
       "607      2       3           0  \n",
       "629      3       3           0  \n",
       "1312     2       0           2  \n",
       "1775     2       0           3  \n",
       "69       2       3           1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.460290Z",
     "iopub.status.busy": "2023-08-26T07:13:17.459815Z",
     "iopub.status.idle": "2023-08-26T07:13:17.474034Z",
     "shell.execute_reply": "2023-08-26T07:13:17.472906Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.460259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   int64  \n",
      " 1   Age                             2111 non-null   int64  \n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   int64  \n",
      " 4   family_history_with_overweight  2111 non-null   int64  \n",
      " 5   FAVC                            2111 non-null   int64  \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   int64  \n",
      " 9   SMOKE                           2111 non-null   int64  \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   int64  \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   int64  \n",
      " 15  MTRANS                          2111 non-null   int64  \n",
      " 16  NObeyesdad                      2111 non-null   int64  \n",
      "dtypes: float64(6), int64(11)\n",
      "memory usage: 280.5 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Different Classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.475975Z",
     "iopub.status.busy": "2023-08-26T07:13:17.475654Z",
     "iopub.status.idle": "2023-08-26T07:13:17.481327Z",
     "shell.execute_reply": "2023-08-26T07:13:17.480259Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.475946Z"
    }
   },
   "outputs": [],
   "source": [
    "x2 = df2.drop(columns=[\"NObeyesdad\"])\n",
    "y2 = df2[\"NObeyesdad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.483410Z",
     "iopub.status.busy": "2023-08-26T07:13:17.483024Z",
     "iopub.status.idle": "2023-08-26T07:13:17.494141Z",
     "shell.execute_reply": "2023-08-26T07:13:17.493108Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.483380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       5\n",
       "4       6\n",
       "       ..\n",
       "2106    4\n",
       "2107    4\n",
       "2108    4\n",
       "2109    4\n",
       "2110    4\n",
       "Name: NObeyesdad, Length: 2111, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.496420Z",
     "iopub.status.busy": "2023-08-26T07:13:17.495495Z",
     "iopub.status.idle": "2023-08-26T07:13:17.502757Z",
     "shell.execute_reply": "2023-08-26T07:13:17.501773Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.496384Z"
    }
   },
   "outputs": [],
   "source": [
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.505214Z",
     "iopub.status.busy": "2023-08-26T07:13:17.504070Z",
     "iopub.status.idle": "2023-08-26T07:13:17.511109Z",
     "shell.execute_reply": "2023-08-26T07:13:17.510477Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.505181Z"
    }
   },
   "outputs": [],
   "source": [
    "log_r2 = LogisticRegression(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.513133Z",
     "iopub.status.busy": "2023-08-26T07:13:17.512327Z",
     "iopub.status.idle": "2023-08-26T07:13:17.620965Z",
     "shell.execute_reply": "2023-08-26T07:13:17.619874Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.513094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_r2.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.622998Z",
     "iopub.status.busy": "2023-08-26T07:13:17.622425Z",
     "iopub.status.idle": "2023-08-26T07:13:17.631682Z",
     "shell.execute_reply": "2023-08-26T07:13:17.630782Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.622964Z"
    }
   },
   "outputs": [],
   "source": [
    "y2_pred_log = log_r2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.633724Z",
     "iopub.status.busy": "2023-08-26T07:13:17.633242Z",
     "iopub.status.idle": "2023-08-26T07:13:17.643105Z",
     "shell.execute_reply": "2023-08-26T07:13:17.641892Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.633692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7210401891252955"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test, y2_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.645206Z",
     "iopub.status.busy": "2023-08-26T07:13:17.644817Z",
     "iopub.status.idle": "2023-08-26T07:13:17.650108Z",
     "shell.execute_reply": "2023-08-26T07:13:17.649037Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.645174Z"
    }
   },
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.652104Z",
     "iopub.status.busy": "2023-08-26T07:13:17.651732Z",
     "iopub.status.idle": "2023-08-26T07:13:17.664554Z",
     "shell.execute_reply": "2023-08-26T07:13:17.663428Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.652072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.666840Z",
     "iopub.status.busy": "2023-08-26T07:13:17.666338Z",
     "iopub.status.idle": "2023-08-26T07:13:17.695531Z",
     "shell.execute_reply": "2023-08-26T07:13:17.694676Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.666807Z"
    }
   },
   "outputs": [],
   "source": [
    "y2_pred_knn = knn2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.697937Z",
     "iopub.status.busy": "2023-08-26T07:13:17.697252Z",
     "iopub.status.idle": "2023-08-26T07:13:17.705437Z",
     "shell.execute_reply": "2023-08-26T07:13:17.704626Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.697896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628841607565012"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test, y2_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.707720Z",
     "iopub.status.busy": "2023-08-26T07:13:17.706982Z",
     "iopub.status.idle": "2023-08-26T07:13:17.713171Z",
     "shell.execute_reply": "2023-08-26T07:13:17.711928Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.707683Z"
    }
   },
   "outputs": [],
   "source": [
    "svm2 = svm.SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.715278Z",
     "iopub.status.busy": "2023-08-26T07:13:17.714955Z",
     "iopub.status.idle": "2023-08-26T07:13:17.863838Z",
     "shell.execute_reply": "2023-08-26T07:13:17.862826Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.715248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.873038Z",
     "iopub.status.busy": "2023-08-26T07:13:17.872760Z",
     "iopub.status.idle": "2023-08-26T07:13:17.887502Z",
     "shell.execute_reply": "2023-08-26T07:13:17.886594Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.873014Z"
    }
   },
   "outputs": [],
   "source": [
    "y2_pred_svm = svm2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.889154Z",
     "iopub.status.busy": "2023-08-26T07:13:17.888683Z",
     "iopub.status.idle": "2023-08-26T07:13:17.898318Z",
     "shell.execute_reply": "2023-08-26T07:13:17.897313Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.889121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581560283687943"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test, y2_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.900276Z",
     "iopub.status.busy": "2023-08-26T07:13:17.899759Z",
     "iopub.status.idle": "2023-08-26T07:13:17.905025Z",
     "shell.execute_reply": "2023-08-26T07:13:17.903955Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.900243Z"
    }
   },
   "outputs": [],
   "source": [
    "naive2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.906834Z",
     "iopub.status.busy": "2023-08-26T07:13:17.906404Z",
     "iopub.status.idle": "2023-08-26T07:13:17.922467Z",
     "shell.execute_reply": "2023-08-26T07:13:17.921493Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.906801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive2.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.924820Z",
     "iopub.status.busy": "2023-08-26T07:13:17.924154Z",
     "iopub.status.idle": "2023-08-26T07:13:17.931224Z",
     "shell.execute_reply": "2023-08-26T07:13:17.930252Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.924789Z"
    }
   },
   "outputs": [],
   "source": [
    "y2_pred_naive = naive2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.933091Z",
     "iopub.status.busy": "2023-08-26T07:13:17.932560Z",
     "iopub.status.idle": "2023-08-26T07:13:17.942696Z",
     "shell.execute_reply": "2023-08-26T07:13:17.941659Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.933059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.541371158392435"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test, y2_pred_naive)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q-3. Imagine you have a dataset where you have different categories of data, Now\n",
    "you need to find the most similar data to the given data by using any 4 different\n",
    "similarity algorithms. Now you have to build a model which can find the most similar\n",
    "data to the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:17.944957Z",
     "iopub.status.busy": "2023-08-26T07:13:17.944466Z",
     "iopub.status.idle": "2023-08-26T07:13:20.079673Z",
     "shell.execute_reply": "2023-08-26T07:13:20.078666Z",
     "shell.execute_reply.started": "2023-08-26T07:13:17.944783Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_3 =  pd.read_json(\"DataSets/News_Category_Dataset_v3.json\", lines=True)\n",
    "\n",
    "df_3 =  pd.read_json(\"https://raw.githubusercontent.com/Dhirengit/PPT-Ineuron/main/DataSets/News_Category_Dataset_v3.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:20.081726Z",
     "iopub.status.busy": "2023-08-26T07:13:20.081341Z",
     "iopub.status.idle": "2023-08-26T07:13:20.088234Z",
     "shell.execute_reply": "2023-08-26T07:13:20.087164Z",
     "shell.execute_reply.started": "2023-08-26T07:13:20.081695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209527, 6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:20.090600Z",
     "iopub.status.busy": "2023-08-26T07:13:20.089914Z",
     "iopub.status.idle": "2023-08-26T07:13:20.113754Z",
     "shell.execute_reply": "2023-08-26T07:13:20.112914Z",
     "shell.execute_reply.started": "2023-08-26T07:13:20.090568Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new = copy.deepcopy(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:20.115557Z",
     "iopub.status.busy": "2023-08-26T07:13:20.115204Z",
     "iopub.status.idle": "2023-08-26T07:13:20.143328Z",
     "shell.execute_reply": "2023-08-26T07:13:20.142335Z",
     "shell.execute_reply.started": "2023-08-26T07:13:20.115524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 6)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new = df_3.sample(1100)\n",
    "df_3_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:20.145181Z",
     "iopub.status.busy": "2023-08-26T07:13:20.144777Z",
     "iopub.status.idle": "2023-08-26T07:13:20.151483Z",
     "shell.execute_reply": "2023-08-26T07:13:20.150407Z",
     "shell.execute_reply.started": "2023-08-26T07:13:20.145150Z"
    }
   },
   "outputs": [],
   "source": [
    "def link_filter(text):\n",
    "    replace_text = text.replace(\"https://www.huffpost.com/entry/\", \"\")\n",
    "    replace_text = replace_text.replace(\"https://www.huffingtonpost.com/entry/\", \"\")\n",
    "    replace_text = replace_text.split(\"_\")[0]\n",
    "    replace_text = re.sub(\"[^a-zA-Z]\", \" \",replace_text )\n",
    "    return replace_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:20.153493Z",
     "iopub.status.busy": "2023-08-26T07:13:20.153096Z",
     "iopub.status.idle": "2023-08-26T07:13:21.194672Z",
     "shell.execute_reply": "2023-08-26T07:13:21.193751Z",
     "shell.execute_reply.started": "2023-08-26T07:13:20.153406Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"link\"]= df_3[\"link\"].apply(link_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:21.196466Z",
     "iopub.status.busy": "2023-08-26T07:13:21.196087Z",
     "iopub.status.idle": "2023-08-26T07:13:21.204148Z",
     "shell.execute_reply": "2023-08-26T07:13:21.203020Z",
     "shell.execute_reply.started": "2023-08-26T07:13:21.196415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 6)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:21.206617Z",
     "iopub.status.busy": "2023-08-26T07:13:21.205917Z",
     "iopub.status.idle": "2023-08-26T07:13:21.213593Z",
     "shell.execute_reply": "2023-08-26T07:13:21.212516Z",
     "shell.execute_reply.started": "2023-08-26T07:13:21.206574Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_preprecess(text, use_stop_word=True):\n",
    "    ps = PorterStemmer()\n",
    "#     wordnet = WordNetLemmatizer()\n",
    "    \n",
    "    tags = nltk.sent_tokenize(text)\n",
    "    tag = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tag = tag.lower()\n",
    "    tag = tag.split()\n",
    "    tag = [ps.stem(word) for word in tag if not word in set(stopwords.words(\"english\"))] if use_stop_word else tag\n",
    "    \n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:21.215544Z",
     "iopub.status.busy": "2023-08-26T07:13:21.215198Z",
     "iopub.status.idle": "2023-08-26T07:13:22.242746Z",
     "shell.execute_reply": "2023-08-26T07:13:22.241772Z",
     "shell.execute_reply.started": "2023-08-26T07:13:21.215512Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"link\"] = df_3_new[\"link\"].apply(text_preprecess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:22.244707Z",
     "iopub.status.busy": "2023-08-26T07:13:22.244323Z",
     "iopub.status.idle": "2023-08-26T07:13:24.021163Z",
     "shell.execute_reply": "2023-08-26T07:13:24.020181Z",
     "shell.execute_reply.started": "2023-08-26T07:13:22.244673Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"headline\"] = df_3_new[\"headline\"].apply(text_preprecess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:24.023277Z",
     "iopub.status.busy": "2023-08-26T07:13:24.022344Z",
     "iopub.status.idle": "2023-08-26T07:13:28.013432Z",
     "shell.execute_reply": "2023-08-26T07:13:28.012431Z",
     "shell.execute_reply.started": "2023-08-26T07:13:24.023248Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"short_description\"] = df_3_new[\"short_description\"].apply(text_preprecess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.015157Z",
     "iopub.status.busy": "2023-08-26T07:13:28.014817Z",
     "iopub.status.idle": "2023-08-26T07:13:28.074435Z",
     "shell.execute_reply": "2023-08-26T07:13:28.073585Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.015121Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"authors\"] = df_3_new[\"authors\"].apply(text_preprecess, use_stop_word=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.077743Z",
     "iopub.status.busy": "2023-08-26T07:13:28.077407Z",
     "iopub.status.idle": "2023-08-26T07:13:28.121713Z",
     "shell.execute_reply": "2023-08-26T07:13:28.120769Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.077719Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"category\"] = df_3_new[\"category\"].apply(text_preprecess, use_stop_word=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.123512Z",
     "iopub.status.busy": "2023-08-26T07:13:28.123099Z",
     "iopub.status.idle": "2023-08-26T07:13:28.137468Z",
     "shell.execute_reply": "2023-08-26T07:13:28.136493Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.123479Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"tags\"] = df_3_new[\"link\"] + df_3_new[\"headline\"] + df_3_new[\"short_description\"] + df_3_new[\"category\"] + df_3_new[\"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.139985Z",
     "iopub.status.busy": "2023-08-26T07:13:28.138934Z",
     "iopub.status.idle": "2023-08-26T07:13:28.148905Z",
     "shell.execute_reply": "2023-08-26T07:13:28.147831Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.139953Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new.drop(columns=[\"link\", \"headline\", \"short_description\", \"category\", \"authors\",\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.150685Z",
     "iopub.status.busy": "2023-08-26T07:13:28.150178Z",
     "iopub.status.idle": "2023-08-26T07:13:28.162607Z",
     "shell.execute_reply": "2023-08-26T07:13:28.161592Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.150652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_new[\"tags\"] = df_3_new[\"tags\"].apply(lambda text : \" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.164606Z",
     "iopub.status.busy": "2023-08-26T07:13:28.164145Z",
     "iopub.status.idle": "2023-08-26T07:13:28.176062Z",
     "shell.execute_reply": "2023-08-26T07:13:28.175134Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.164536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.177912Z",
     "iopub.status.busy": "2023-08-26T07:13:28.177569Z",
     "iopub.status.idle": "2023-08-26T07:13:28.191265Z",
     "shell.execute_reply": "2023-08-26T07:13:28.190392Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.177860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118047</th>\n",
       "      <td>american educ test matter test score stop obse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171750</th>\n",
       "      <td>girl stem mentorship girl stem call mentor tog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68483</th>\n",
       "      <td>radiohead drop new singl burn witch onlin radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180974</th>\n",
       "      <td>uga footbal script murray determin championshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122097</th>\n",
       "      <td>kendal jenner text vma kendal jenner address v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68346</th>\n",
       "      <td>chloe grace moretz throw around lot buzzword a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79723</th>\n",
       "      <td>peni pump exchang pistol man pull gun clerk fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147965</th>\n",
       "      <td>mental health new psychiatri forget everyth th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65560</th>\n",
       "      <td>daili medit spiritu susten daili medit spiritu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28118</th>\n",
       "      <td>life horribl social media standard life horrib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tags\n",
       "118047  american educ test matter test score stop obse...\n",
       "171750  girl stem mentorship girl stem call mentor tog...\n",
       "68483   radiohead drop new singl burn witch onlin radi...\n",
       "180974  uga footbal script murray determin championshi...\n",
       "122097  kendal jenner text vma kendal jenner address v...\n",
       "...                                                   ...\n",
       "68346   chloe grace moretz throw around lot buzzword a...\n",
       "79723   peni pump exchang pistol man pull gun clerk fa...\n",
       "147965  mental health new psychiatri forget everyth th...\n",
       "65560   daili medit spiritu susten daili medit spiritu...\n",
       "28118   life horribl social media standard life horrib...\n",
       "\n",
       "[1100 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.193182Z",
     "iopub.status.busy": "2023-08-26T07:13:28.192786Z",
     "iopub.status.idle": "2023-08-26T07:13:28.200657Z",
     "shell.execute_reply": "2023-08-26T07:13:28.199741Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.193151Z"
    }
   },
   "outputs": [],
   "source": [
    "cv3 = CountVectorizer(max_features=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.202624Z",
     "iopub.status.busy": "2023-08-26T07:13:28.202078Z",
     "iopub.status.idle": "2023-08-26T07:13:28.271341Z",
     "shell.execute_reply": "2023-08-26T07:13:28.270335Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.202577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 1500)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = cv3.fit_transform(df_3_new[\"tags\"]).toarray()\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.272935Z",
     "iopub.status.busy": "2023-08-26T07:13:28.272575Z",
     "iopub.status.idle": "2023-08-26T07:13:28.333101Z",
     "shell.execute_reply": "2023-08-26T07:13:28.331596Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.272903Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.335041Z",
     "iopub.status.busy": "2023-08-26T07:13:28.334689Z",
     "iopub.status.idle": "2023-08-26T07:13:28.345160Z",
     "shell.execute_reply": "2023-08-26T07:13:28.343898Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.335004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.07537784, 0.07756315, ..., 0.09656091, 0.        ,\n",
       "        0.05330018],\n",
       "       [0.07537784, 1.        , 0.08574929, ..., 0.02668803, 0.        ,\n",
       "        0.        ],\n",
       "       [0.07756315, 0.08574929, 1.        , ..., 0.10984701, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.09656091, 0.02668803, 0.10984701, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.05330018, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.347137Z",
     "iopub.status.busy": "2023-08-26T07:13:28.346618Z",
     "iopub.status.idle": "2023-08-26T07:13:28.354878Z",
     "shell.execute_reply": "2023-08-26T07:13:28.353641Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.347093Z"
    }
   },
   "outputs": [],
   "source": [
    "# def euclidean_distance(point1, point2):\n",
    "#     return np.linalg.norm(point1 - point2)\n",
    "\n",
    "# # Function to find the most similar data point using Euclidean distance\n",
    "# def find_most_similar_data(dataset, given_data):\n",
    "#     distances = [euclidean_distance(given_data, data) for data in dataset]\n",
    "#     most_similar_index = np.argmin(distances)\n",
    "#     return dataset[most_similar_index]\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# given_data = vector[0]  # The point for which we want to find the most similar point\n",
    "# most_similar_data = find_most_similar_data(vector, given_data)\n",
    "\n",
    "# print(\"Given data point:\", given_data, vector.shape)\n",
    "# print(\"Most similar data point:\", most_similar_data, given_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:28.356930Z",
     "iopub.status.busy": "2023-08-26T07:13:28.356596Z",
     "iopub.status.idle": "2023-08-26T07:13:42.557153Z",
     "shell.execute_reply": "2023-08-26T07:13:42.555976Z",
     "shell.execute_reply.started": "2023-08-26T07:13:28.356899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 max_similarity 0.07537783614444091\n",
      "0 2 max_similarity 0.07756315349925287\n",
      "0 64 max_similarity 0.21661214442955293\n",
      "0 808 max_similarity 0.43684887642861214\n",
      "9 35 max_similarity 0.5863527298559492\n",
      "37 241 max_similarity 0.5936657514041415\n",
      "41 183 max_similarity 0.653358607776565\n",
      "41 216 max_similarity 0.6634888026970371\n",
      "62 117 max_similarity 0.6842105263157894\n",
      "62 848 max_similarity 0.7029594915666377\n",
      "68 782 max_similarity 0.7249999999999999\n",
      "117 848 max_similarity 0.7570332986102252\n",
      "Cosine Most similar pair: (117, 848)\n",
      "Cosine Similarity score: 0.7570332986102252\n"
     ]
    }
   ],
   "source": [
    "data_array = vector\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "max_similarity = -1\n",
    "most_similar_pair = (0, 0)\n",
    "\n",
    "for i in range(len(data_array)):\n",
    "    for j in range(i + 1, len(data_array)):\n",
    "        similarity = cosine_similarity(data_array[i], data_array[j])\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pair = (i, j)\n",
    "            print(i,j,\"max_similarity\", max_similarity)\n",
    "\n",
    "\n",
    "print(\"Cosine Most similar pair:\", most_similar_pair)\n",
    "print(\"Cosine Similarity score:\", max_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:42.561344Z",
     "iopub.status.busy": "2023-08-26T07:13:42.560316Z",
     "iopub.status.idle": "2023-08-26T07:13:42.571012Z",
     "shell.execute_reply": "2023-08-26T07:13:42.568718Z",
     "shell.execute_reply.started": "2023-08-26T07:13:42.561305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tags    maggi hutchason gp guid maggi hutchason gp gui...\n",
       " Name: 74017, dtype: object,\n",
       " tags    ronda lacroix gp guid ronda lacroix gp guid le...\n",
       " Name: 72807, dtype: object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new.iloc[most_similar_pair[0]], df_3_new.iloc[most_similar_pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:42.573206Z",
     "iopub.status.busy": "2023-08-26T07:13:42.572625Z",
     "iopub.status.idle": "2023-08-26T07:13:52.513829Z",
     "shell.execute_reply": "2023-08-26T07:13:52.512712Z",
     "shell.execute_reply.started": "2023-08-26T07:13:42.573171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 max_similarity 0.10414144201428256\n",
      "0 2 max_similarity 0.10542649822871226\n",
      "0 3 max_similarity 0.11268865367232477\n",
      "0 4 max_similarity 0.12178632452799958\n",
      "0 16 max_similarity 0.12389934309929541\n",
      "0 139 max_similarity 0.125\n",
      "0 208 max_similarity 0.1261319836228832\n",
      "0 878 max_similarity 0.12729683913915313\n",
      "1 4 max_similarity 0.13100580420257674\n",
      "1 16 max_similarity 0.13367660240019172\n",
      "1 208 max_similarity 0.1365270594958143\n",
      "1 878 max_similarity 0.1380262631157473\n",
      "2 208 max_similarity 0.13957875683699938\n",
      "2 404 max_similarity 0.14285714285714285\n",
      "3 4 max_similarity 0.1639607805437114\n",
      "3 16 max_similarity 0.1757340838011157\n",
      "3 591 max_similarity 0.1827439976315568\n",
      "3 878 max_similarity 0.1951941016011038\n",
      "4 16 max_similarity 0.21089672205953397\n",
      "4 208 max_similarity 0.2240092377397959\n",
      "4 878 max_similarity 0.23166247903554\n",
      "16 208 max_similarity 0.2402530733520421\n",
      "16 878 max_similarity 0.25\n",
      "20 25 max_similarity 0.27429188517743175\n",
      "1036 1044 max_similarity 0.28989794855663564\n",
      "Euclidean Most Similar pair: (1036, 1044)\n",
      "Euclidean Similarity score: 0.28989794855663564\n"
     ]
    }
   ],
   "source": [
    "max_similarity= -1\n",
    "most_similar_pair = (0, 0)\n",
    "\n",
    "for i in range(len(data_array)):\n",
    "    for j in range(i + 1, len(data_array)):\n",
    "        distance = euclidean(data_array[i], data_array[j])\n",
    "        similarity = 1 / (1 + distance)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_pair = (i, j)\n",
    "            print(i,j,\"max_similarity\", max_similarity)\n",
    "     \n",
    "print(\"Euclidean Most Similar pair:\", most_similar_pair)\n",
    "print(\"Euclidean Similarity score:\", max_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:52.517530Z",
     "iopub.status.busy": "2023-08-26T07:13:52.516380Z",
     "iopub.status.idle": "2023-08-26T07:13:52.526045Z",
     "shell.execute_reply": "2023-08-26T07:13:52.524929Z",
     "shell.execute_reply.started": "2023-08-26T07:13:52.517491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tags    bailey dessert recip bailey dessert recip phot...\n",
       " Name: 171371, dtype: object,\n",
       " tags    bruschetta recip bruschetta crostini recip way...\n",
       " Name: 154750, dtype: object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new.iloc[most_similar_pair[0]], df_3_new.iloc[most_similar_pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:13:52.528210Z",
     "iopub.status.busy": "2023-08-26T07:13:52.527784Z",
     "iopub.status.idle": "2023-08-26T07:14:06.364109Z",
     "shell.execute_reply": "2023-08-26T07:14:06.362346Z",
     "shell.execute_reply.started": "2023-08-26T07:13:52.528171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.09090909090909094\n",
      "0 249 0.09302325581395354\n",
      "0 763 0.09999999999999998\n",
      "0 819 0.10344827586206895\n",
      "1 559 0.11111111111111116\n",
      "2 329 0.125\n",
      "4 149 0.16666666666666663\n",
      "4 496 0.2222222222222222\n",
      "4 646 0.25\n",
      "18 90 0.2692307692307693\n",
      "36 461 0.2727272727272727\n",
      "37 241 0.2962962962962963\n",
      "45 289 0.3076923076923077\n",
      "45 1044 0.4\n",
      "62 117 0.4375\n",
      "62 848 0.4666666666666667\n",
      "117 848 0.47058823529411764\n",
      "1036 1044 0.625\n",
      "Jaccard Most similar rows: 1036 and 1044\n",
      "Jaccard similarity score: 0.625\n"
     ]
    }
   ],
   "source": [
    "#Jaccard Similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    similarity = intersection / union\n",
    "    return similarity\n",
    "\n",
    "most_similar_row = None\n",
    "max_similarity = -1\n",
    "\n",
    "for i in range(data_array.shape[0]):\n",
    "    for j in range(i+1 , data_array.shape[0]):\n",
    "        jaccard_similarity = 1 - jaccard(data_array[i], data_array[j])\n",
    "        if jaccard_similarity > max_similarity:\n",
    "            max_similarity = jaccard_similarity\n",
    "            most_similar_row = i, j\n",
    "            print(i,j, max_similarity)\n",
    "            \n",
    "\n",
    "# Print the indices of the most similar rows and their Jaccard similarity score\n",
    "print(f\"Jaccard Most similar rows: {most_similar_row[0]} and {most_similar_row[1]}\")\n",
    "print(f\"Jaccard similarity score: {max_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:14:06.366021Z",
     "iopub.status.busy": "2023-08-26T07:14:06.365398Z",
     "iopub.status.idle": "2023-08-26T07:14:06.374973Z",
     "shell.execute_reply": "2023-08-26T07:14:06.373814Z",
     "shell.execute_reply.started": "2023-08-26T07:14:06.365984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tags    bailey dessert recip bailey dessert recip phot...\n",
       " Name: 171371, dtype: object,\n",
       " tags    bruschetta recip bruschetta crostini recip way...\n",
       " Name: 154750, dtype: object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_new.iloc[most_similar_row[0]], df_3_new.iloc[most_similar_row[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**correlation between Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:14:42.616907Z",
     "iopub.status.busy": "2023-08-26T07:14:42.616515Z",
     "iopub.status.idle": "2023-08-26T07:14:42.622306Z",
     "shell.execute_reply": "2023-08-26T07:14:42.620740Z",
     "shell.execute_reply.started": "2023-08-26T07:14:42.616877Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean, jaccard, hamming, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:16:05.999268Z",
     "iopub.status.busy": "2023-08-26T07:16:05.998426Z",
     "iopub.status.idle": "2023-08-26T07:16:06.009406Z",
     "shell.execute_reply": "2023-08-26T07:16:06.008360Z",
     "shell.execute_reply.started": "2023-08-26T07:16:05.999230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(data_array[1], data_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T07:24:27.659690Z",
     "iopub.status.busy": "2023-08-26T07:24:27.657577Z",
     "iopub.status.idle": "2023-08-26T07:25:35.522917Z",
     "shell.execute_reply": "2023-08-26T07:25:35.521964Z",
     "shell.execute_reply.started": "2023-08-26T07:24:27.659655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.0675395757752667\n",
      "0 2 0.0704368634312007\n",
      "0 64 0.20906268151013174\n",
      "0 808 0.4306051840817928\n",
      "9 35 0.5840300542665204\n",
      "37 241 0.5901806862965344\n",
      "41 183 0.6509584812121509\n",
      "41 216 0.661026778441497\n",
      "62 117 0.6820835051740806\n",
      "62 848 0.7010216085909317\n",
      "68 782 0.7236056945949022\n",
      "117 848 0.7551850396091573\n",
      "Most correlation similar rows: 117 and 848\n",
      "correlation similarity score: 0.7551850396091573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tags    maggi hutchason gp guid maggi hutchason gp gui...\n",
       " Name: 74017, dtype: object,\n",
       " tags    ronda lacroix gp guid ronda lacroix gp guid le...\n",
       " Name: 72807, dtype: object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_row = None\n",
    "max_correlation = -1\n",
    "\n",
    "for i in range(data_array.shape[0]):\n",
    "    for j in range(i+1 , data_array.shape[0]):\n",
    "        corr = 1 - correlation(data_array[i], data_array[j])\n",
    "        if corr > max_correlation:\n",
    "            max_correlation = corr\n",
    "            most_similar_row = i, j\n",
    "            print(i,j, max_correlation)\n",
    "            \n",
    "\n",
    "# Print the indices of the most similar rows and their Jaccard similarity score\n",
    "print(f\"Most correlation similar rows: {most_similar_row[0]} and {most_similar_row[1]}\")\n",
    "print(f\"correlation similarity score: {max_correlation}\")\n",
    "\n",
    "df_3_new.iloc[most_similar_row[0]], df_3_new.iloc[most_similar_row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-26T07:14:06.416354Z",
     "iopub.status.idle": "2023-08-26T07:14:06.417215Z",
     "shell.execute_reply": "2023-08-26T07:14:06.416986Z",
     "shell.execute_reply.started": "2023-08-26T07:14:06.416964Z"
    }
   },
   "outputs": [],
   "source": [
    "# import Levenshtein\n",
    "# def levenshtein_similarity(row1, row2):\n",
    "#     return 1 - (Levenshtein.distance(row1, row2) / max(len(row1), len(row2)))\n",
    "\n",
    "# most_similar_row = None\n",
    "# max_similarity = -1\n",
    "\n",
    "# for i in range(data_array.shape[0]):\n",
    "#     for j in range(i + 1, data_array.shape[0]):\n",
    "#         similarity = levenshtein_similarity(data_array[i], data_array[j])\n",
    "#         if similarity > max_similarity:\n",
    "#             max_similarity = similarity\n",
    "#             most_similar_row = (i, j)\n",
    "#             print(i,j, max_similarity)\n",
    "\n",
    "# print(f\"Most similar rows: {most_similar_row}\")\n",
    "# print(f\"Similarity score: {max_similarity}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q-4. Imagine you working as a sale manager now you need to predict the Revenue\n",
    "and whether that particular revenue is on the weekend or not and find the\n",
    "Informational_Duration using the Ensemble learning algorithm\n",
    "Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_csv(\"DataSets/online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
