{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lBWjTH7EVO2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, DepthwiseConv2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 -\n",
        "Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
        "dataset using the Tensorflow library.\n",
        "Note -\n",
        "1. The model parameters for each architecture should not be more than 8000\n",
        "parameters\n",
        "2. Code comments should be given for proper code understanding.\n",
        "3. The minimum accuracy for each accuracy should be at least 96%"
      ],
      "metadata": {
        "id": "M7GR6oOHEXMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "0qKs31Q4EYkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5c7146-c0de-42bc-bdf8-f8d104422d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwvRH_gnFd4r",
        "outputId": "c2605bb4-eab5-44d9-95d3-b7f78effe590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalise the pixel values to range 0-1 and reshape\n",
        "x_train = x_train.reshape((x_train.shape[0], 28,28,1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0],28,28,1)).astype('float32') / 255"
      ],
      "metadata": {
        "id": "luQOv2E2NVzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding the lables\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "ClCDDdmVSFHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Architecture 1: Small CNN with 6,810 parameters\n",
        "model1 = models.Sequential([\n",
        "    layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Architecture 2: Depthwise CNN with 6,650  parameters\n",
        "model2 = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Architecture 3: Strided CNN with 5,930 parameters\n",
        "model3 = models.Sequential([\n",
        "    layers.Conv2D(20, (3, 3), strides=(2,2), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Function to compile, train, and evaluate models\n",
        "def train_and_evaluate(model, x_train, y_train, x_test, y_test, optimizer='adam', epochs=5, batch_size=64):\n",
        "    print(\"optimizer\", optimizer, \"epochs\", epochs, \"batch_size\", batch_size)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return test_acc, model.count_params()\n",
        "\n",
        "# Train and evaluate all models\n",
        "results = {}\n",
        "models_list = [model1, model2, model3]\n",
        "model_names = ['Model 1', 'Model 2', 'Model 3']\n",
        "optimizers = ['adam', 'sgd', 'rmsprop']\n",
        "epochs = [15, 10, 7]\n",
        "\n",
        "for model, name, optimizer, epoch in zip(models_list, model_names, optimizers, epochs):\n",
        "    acc, params = train_and_evaluate(model, x_train, y_train, x_test, y_test, optimizer, epoch)\n",
        "    results[name] = {'Accuracy': acc, 'Parameters': params, 'Optimizer':optimizer}\n",
        "\n",
        "# Print results in a comparison table\n",
        "print(f\"{'Model':<10} {'Accuracy':<10} {'Parameters':<10} {'Optimizer':<10}\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model:<10} {metrics['Accuracy']:<10.4f} {metrics['Parameters']:<10} {metrics['Optimizer']:10}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaKgJOXfW3qa",
        "outputId": "cdc266ba-16d8-41d2-88ba-507e3df8bf0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizer adam epochs 15 batch_size 64\n",
            "optimizer sgd epochs 10 batch_size 64\n",
            "optimizer rmsprop epochs 7 batch_size 64\n",
            "Model      Accuracy   Parameters Optimizer \n",
            "Model 1    0.9728     6810       adam      \n",
            "Model 2    0.9758     6650       sgd       \n",
            "Model 3    0.9732     7410       rmsprop   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 -\n",
        "Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
        "dataset using the PyTorch library\n",
        "Note -\n",
        "1. The model parameters for each architecture should not be more than 10000\n",
        "parameters\n",
        "2. Code comments should be given for proper code understanding"
      ],
      "metadata": {
        "id": "6oX3ruaGVLPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from time import time"
      ],
      "metadata": {
        "id": "WK2M4OAv1hlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"using Device {device}\")\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"cuda name is {torch.cuda.get_device_name(0)}\")\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(train_dataset.data.shape[1:])\n",
        "print(train_loader.dataset.data.shape[1:])"
      ],
      "metadata": {
        "id": "WhjoDkeKNGM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bad10f-08ba-4970-c603-97a4a71f2f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using Device cpu\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "I7g8M3bvv2nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=8, out_channels=13, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(13 * 8 * 8, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1), # (input_width - Filter_size + 2(padding)) / Stripe + 1 = (32 - 3 + 2(0)) / 2 + 1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2), # = (16-2)/1 +1\n",
        "        nn.Conv2d(in_channels=16, out_channels=31, kernel_size=3, stride=2, padding=1), # (16 - 3)  / 1 +1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(31 * 4 * 4, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN3, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=14, kernel_size=3, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(14 * 8 * 8, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      return x\n",
        "\n",
        "class CNN4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN4, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(16 * 7 * 7, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class CNN5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN5, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=6, out_channels=14, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(14 * 8 * 8, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UufguWOu0nJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer_name='adam', epochs=5, lr=0.001):\n",
        "  model_name = model.__class__.__name__\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  if optimizer_name.lower() == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'sgd':\n",
        "      optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'rms':\n",
        "      optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'adadelta':\n",
        "      optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'adagrad':\n",
        "      optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid optimizer name. Choose from 'adam', 'sgd', 'rms', 'adadelta' or 'adagrad'.\")\n",
        "  start_time = time()\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if (i + 1) % 1500 == 0:\n",
        "              print(f'{model_name} Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "  end_time = time()\n",
        "  print(f\"Model name: {model_name}, Training time: {(end_time - start_time):.2f}s\")\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      accuracy = 100 * correct / total\n",
        "      print(f'Accuracy of the model {model_name} on the test images: {accuracy:.2f}%')\n",
        "      return accuracy, count_trainable_params(model), end_time - start_time\n"
      ],
      "metadata": {
        "id": "Eg2iMIqc0nOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate all models\n",
        "results = {}\n",
        "models_list = [CNN1(), CNN2(), CNN3(), CNN4(), CNN5()]\n",
        "model_names = ['Model_1','Model_2', 'Model_3', 'Model_4', 'Model_5']\n",
        "optimizers = ['rms', 'adam', 'sgd', 'adadelta', 'adagrad']\n",
        "epochs = [5, 5, 10, 10, 10]\n",
        "\n",
        "for model, name, optimizer, epoch in zip(models_list, model_names, optimizers, epochs):\n",
        "    acc, params, training_time = train_and_evaluate(model, optimizer, epoch)\n",
        "    results[name] = {'Accuracy': acc, 'Parameters': params, 'Optimizer':optimizer, 'training_time': training_time}\n",
        "\n",
        "# Print results in a comparison table\n",
        "print(f\"{'Model':<10} {'Accuracy':<10} {'Parameters':<10} {'Optimizer':<10} {'Training time':<10}\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model:<10} {metrics['Accuracy']:<10.3f} {metrics['Parameters']:<10} {metrics['Optimizer']:10} {metrics['training_time']:10.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7MMT0x71CHk",
        "outputId": "6ce6f8e3-df6b-4720-8d55-1e41c683eb16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN1 Epoch [1/5], Step [1500/1563], Loss: 1.4610\n",
            "CNN1 Epoch [2/5], Step [1500/1563], Loss: 1.0808\n",
            "CNN1 Epoch [3/5], Step [1500/1563], Loss: 1.0839\n",
            "CNN1 Epoch [4/5], Step [1500/1563], Loss: 0.6931\n",
            "CNN1 Epoch [5/5], Step [1500/1563], Loss: 1.1944\n",
            "Model name: CNN1, Training time: 167.77s\n",
            "Accuracy of the model CNN1 on the test images: 58.99%\n",
            "CNN2 Epoch [1/5], Step [1500/1563], Loss: 1.2476\n",
            "CNN2 Epoch [2/5], Step [1500/1563], Loss: 1.4029\n",
            "CNN2 Epoch [3/5], Step [1500/1563], Loss: 1.1941\n",
            "CNN2 Epoch [4/5], Step [1500/1563], Loss: 1.2674\n",
            "CNN2 Epoch [5/5], Step [1500/1563], Loss: 0.7123\n",
            "Model name: CNN2, Training time: 203.52s\n",
            "Accuracy of the model CNN2 on the test images: 64.75%\n",
            "CNN3 Epoch [1/10], Step [1500/1563], Loss: 1.9556\n",
            "CNN3 Epoch [2/10], Step [1500/1563], Loss: 2.1128\n",
            "CNN3 Epoch [3/10], Step [1500/1563], Loss: 1.7514\n",
            "CNN3 Epoch [4/10], Step [1500/1563], Loss: 1.7471\n",
            "CNN3 Epoch [5/10], Step [1500/1563], Loss: 1.5929\n",
            "CNN3 Epoch [6/10], Step [1500/1563], Loss: 1.7503\n",
            "CNN3 Epoch [7/10], Step [1500/1563], Loss: 1.5996\n",
            "CNN3 Epoch [8/10], Step [1500/1563], Loss: 1.7642\n",
            "CNN3 Epoch [9/10], Step [1500/1563], Loss: 1.5292\n",
            "CNN3 Epoch [10/10], Step [1500/1563], Loss: 1.5751\n",
            "Model name: CNN3, Training time: 227.16s\n",
            "Accuracy of the model CNN3 on the test images: 43.64%\n",
            "CNN4 Epoch [1/10], Step [1500/1563], Loss: 2.2691\n",
            "CNN4 Epoch [2/10], Step [1500/1563], Loss: 2.2562\n",
            "CNN4 Epoch [3/10], Step [1500/1563], Loss: 2.2043\n",
            "CNN4 Epoch [4/10], Step [1500/1563], Loss: 2.2207\n",
            "CNN4 Epoch [5/10], Step [1500/1563], Loss: 2.0295\n",
            "CNN4 Epoch [6/10], Step [1500/1563], Loss: 2.0506\n",
            "CNN4 Epoch [7/10], Step [1500/1563], Loss: 2.1001\n",
            "CNN4 Epoch [8/10], Step [1500/1563], Loss: 1.9796\n",
            "CNN4 Epoch [9/10], Step [1500/1563], Loss: 2.0757\n",
            "CNN4 Epoch [10/10], Step [1500/1563], Loss: 1.9766\n",
            "Model name: CNN4, Training time: 232.21s\n",
            "Accuracy of the model CNN4 on the test images: 30.32%\n",
            "Model      Accuracy   Parameters Optimizer  Training time\n",
            "Model_1    58.990     9503       rms            167.77\n",
            "Model_2    64.750     9913       adam           203.52\n",
            "Model_3    43.640     9362       sgd            227.16\n",
            "Model_4    30.320     8298       adadelta       232.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uz2V4ylo0nR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "suzRn9Ig0nVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-oNkjOy0nY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}