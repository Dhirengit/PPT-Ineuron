{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1lBWjTH7EVO2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, DepthwiseConv2D\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7GR6oOHEXMW"
      },
      "source": [
        "Question 1 -\n",
        "Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
        "dataset using the Tensorflow library.\n",
        "Note -\n",
        "1. The model parameters for each architecture should not be more than 8000\n",
        "parameters\n",
        "2. Code comments should be given for proper code understanding.\n",
        "3. The minimum accuracy for each accuracy should be at least 96%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qKs31Q4EYkn",
        "outputId": "541a3805-eba3-4d78-d063-31e35c4b1610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwvRH_gnFd4r",
        "outputId": "2b5ceda6-a6d2-4c08-df70-0cf245857dd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "luQOv2E2NVzU"
      },
      "outputs": [],
      "source": [
        "# Normalise the pixel values to range 0-1 and reshape\n",
        "x_train = x_train.reshape((x_train.shape[0], 28,28,1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0],28,28,1)).astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ClCDDdmVSFHD"
      },
      "outputs": [],
      "source": [
        "#one hot encoding the lables\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaKgJOXfW3qa",
        "outputId": "569c5698-17fb-4eef-b485-468354c59e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizer adam epochs 15 batch_size 64\n",
            "optimizer sgd epochs 10 batch_size 64\n",
            "optimizer rmsprop epochs 7 batch_size 64\n",
            "Model      Accuracy   Parameters Optimizer \n",
            "Model 1    0.9699     6810       adam      \n",
            "Model 2    0.9800     6650       sgd       \n",
            "Model 3    0.9735     7410       rmsprop   \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Architecture 1: Small CNN with 6,810 parameters\n",
        "model1 = models.Sequential([\n",
        "    layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Architecture 2: Depthwise CNN with 6,650  parameters\n",
        "model2 = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.DepthwiseConv2D((3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Architecture 3: Strided CNN with 5,930 parameters\n",
        "model3 = models.Sequential([\n",
        "    layers.Conv2D(20, (3, 3), strides=(2,2), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Function to compile, train, and evaluate models\n",
        "def train_and_evaluate(model, x_train, y_train, x_test, y_test, optimizer='adam', epochs=5, batch_size=64):\n",
        "    print(\"optimizer\", optimizer, \"epochs\", epochs, \"batch_size\", batch_size)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return test_acc, model.count_params()\n",
        "\n",
        "# Train and evaluate all models\n",
        "results = {}\n",
        "models_list = [model1, model2, model3]\n",
        "model_names = ['Model 1', 'Model 2', 'Model 3']\n",
        "optimizers = ['adam', 'sgd', 'rmsprop']\n",
        "epochs = [15, 10, 7]\n",
        "\n",
        "for model, name, optimizer, epoch in zip(models_list, model_names, optimizers, epochs):\n",
        "    acc, params = train_and_evaluate(model, x_train, y_train, x_test, y_test, optimizer, epoch)\n",
        "    results[name] = {'Accuracy': acc, 'Parameters': params, 'Optimizer':optimizer}\n",
        "\n",
        "# Print results in a comparison table\n",
        "print(f\"{'Model':<10} {'Accuracy':<10} {'Parameters':<10} {'Optimizer':<10}\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model:<10} {metrics['Accuracy']:<10.4f} {metrics['Parameters']:<10} {metrics['Optimizer']:10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oX3ruaGVLPT"
      },
      "source": [
        "Question 2 -\n",
        "Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
        "dataset using the PyTorch library\n",
        "Note -\n",
        "1. The model parameters for each architecture should not be more than 10000\n",
        "parameters\n",
        "2. Code comments should be given for proper code understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhjoDkeKNGM8",
        "outputId": "30cd6053-2707-4909-f68e-bc0c8d874452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using Device cuda\n",
            "cuda name is Tesla T4\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"using Device {device}\")\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"cuda name is {torch.cuda.get_device_name(0)}\")\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(train_dataset.data.shape[1:])\n",
        "print(train_loader.dataset.data.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I7g8M3bvv2nL"
      },
      "outputs": [],
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UufguWOu0nJ_"
      },
      "outputs": [],
      "source": [
        "class CNN1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=8, out_channels=13, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(13 * 8 * 8, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1), # (input_width - Filter_size + 2(padding)) / Stripe + 1 = (32 - 3 + 2(0)) / 2 + 1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2), # = (16-2)/1 +1\n",
        "        nn.Conv2d(in_channels=16, out_channels=31, kernel_size=3, stride=2, padding=1), # (16 - 3)  / 1 +1\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(31 * 4 * 4, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class CNN3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN3, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=14, kernel_size=3, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(14 * 8 * 8, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      return x\n",
        "\n",
        "class CNN4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN4, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(16 * 7 * 7, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class CNN5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN5, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(in_channels=6, out_channels=14, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(14 * 8 * 8, 10)\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Eg2iMIqc0nOB"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, optimizer_name='adam', epochs=5, lr=0.001):\n",
        "  model_name = model.__class__.__name__\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  if optimizer_name.lower() == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'sgd':\n",
        "      optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'rms':\n",
        "      optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'adadelta':\n",
        "      optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "  elif optimizer_name.lower() == 'adagrad':\n",
        "      optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid optimizer name. Choose from 'adam', 'sgd', 'rms', 'adadelta' or 'adagrad'.\")\n",
        "  start_time = time()\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if (i + 1) % 1500 == 0:\n",
        "              print(f'{model_name} Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "  end_time = time()\n",
        "  print(f\"Model name: {model_name}, Training time: {(end_time - start_time):.2f}s\")\n",
        "\n",
        "  # Evaluation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      accuracy = 100 * correct / total\n",
        "      print(f'Accuracy of the model {model_name} on the test images: {accuracy:.2f}%')\n",
        "      return accuracy, count_trainable_params(model), end_time - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7MMT0x71CHk",
        "outputId": "b005ee0d-2442-4ef9-9569-220faec20a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN1 Epoch [1/5], Step [1500/1563], Loss: 1.6611\n",
            "CNN1 Epoch [2/5], Step [1500/1563], Loss: 1.4203\n",
            "CNN1 Epoch [3/5], Step [1500/1563], Loss: 1.0885\n",
            "CNN1 Epoch [4/5], Step [1500/1563], Loss: 0.8662\n",
            "CNN1 Epoch [5/5], Step [1500/1563], Loss: 1.0304\n",
            "Model name: CNN1, Training time: 76.94s\n",
            "Accuracy of the model CNN1 on the test images: 60.49%\n",
            "CNN2 Epoch [1/5], Step [1500/1563], Loss: 1.2516\n",
            "CNN2 Epoch [2/5], Step [1500/1563], Loss: 1.1318\n",
            "CNN2 Epoch [3/5], Step [1500/1563], Loss: 0.9055\n",
            "CNN2 Epoch [4/5], Step [1500/1563], Loss: 0.8212\n",
            "CNN2 Epoch [5/5], Step [1500/1563], Loss: 1.0036\n",
            "Model name: CNN2, Training time: 77.24s\n",
            "Accuracy of the model CNN2 on the test images: 64.43%\n",
            "CNN3 Epoch [1/5], Step [1500/1563], Loss: 1.9959\n",
            "CNN3 Epoch [2/5], Step [1500/1563], Loss: 1.8903\n",
            "CNN3 Epoch [3/5], Step [1500/1563], Loss: 1.7466\n",
            "CNN3 Epoch [4/5], Step [1500/1563], Loss: 1.5043\n",
            "CNN3 Epoch [5/5], Step [1500/1563], Loss: 1.7190\n",
            "Model name: CNN3, Training time: 72.44s\n",
            "Accuracy of the model CNN3 on the test images: 39.86%\n",
            "CNN4 Epoch [1/5], Step [1500/1563], Loss: 1.3494\n",
            "CNN4 Epoch [2/5], Step [1500/1563], Loss: 1.0397\n",
            "CNN4 Epoch [3/5], Step [1500/1563], Loss: 1.3436\n",
            "CNN4 Epoch [4/5], Step [1500/1563], Loss: 1.3976\n",
            "CNN4 Epoch [5/5], Step [1500/1563], Loss: 1.5242\n",
            "Model name: CNN4, Training time: 73.99s\n",
            "Accuracy of the model CNN4 on the test images: 57.73%\n",
            "CNN5 Epoch [1/5], Step [1500/1563], Loss: 1.5892\n",
            "CNN5 Epoch [2/5], Step [1500/1563], Loss: 1.5531\n",
            "CNN5 Epoch [3/5], Step [1500/1563], Loss: 1.3632\n",
            "CNN5 Epoch [4/5], Step [1500/1563], Loss: 1.0398\n",
            "CNN5 Epoch [5/5], Step [1500/1563], Loss: 0.8151\n",
            "Model name: CNN5, Training time: 77.35s\n",
            "Accuracy of the model CNN5 on the test images: 60.89%\n",
            "Model      Accuracy   Parameters Optimizer  Training time\n",
            "Model_1    60.490     9503       rms             76.94\n",
            "Model_2    64.430     9913       adam            77.24\n",
            "Model_3    39.860     9362       sgd             72.44\n",
            "Model_4    57.730     8298       adam            73.99\n",
            "Model_5    60.890     9908       adam            77.35\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate all models\n",
        "results = {}\n",
        "models_list = [CNN1(), CNN2(), CNN3(), CNN4(), CNN5()]\n",
        "model_names = ['Model_1','Model_2', 'Model_3', 'Model_4', 'Model_5']\n",
        "optimizers = ['rms', 'adam', 'sgd', 'adam', 'adam']\n",
        "epochs = [5, 5, 5, 5, 5]\n",
        "\n",
        "for model, name, optimizer, epoch in zip(models_list, model_names, optimizers, epochs):\n",
        "    acc, params, training_time = train_and_evaluate(model, optimizer, epoch)\n",
        "    results[name] = {'Accuracy': acc, 'Parameters': params, 'Optimizer':optimizer, 'training_time': training_time}\n",
        "\n",
        "# Print results in a comparison table\n",
        "print(f\"{'Model':<10} {'Accuracy':<10} {'Parameters':<10} {'Optimizer':<10} {'Training time':<10}\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model:<10} {metrics['Accuracy']:<10.3f} {metrics['Parameters']:<10} {metrics['Optimizer']:10} {metrics['training_time']:10.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHOj5hp1s51H"
      },
      "source": [
        "Question 3 -\n",
        "Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
        "Dataset having minimum validation accuracy of 99.40%\n",
        "Note -\n",
        "1. Code comments should be given for proper code understanding.\n",
        "2. Implement in both PyTorch and Tensorflow respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uz2V4ylo0nR6"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalise the pixel values to range 0-1 and reshape\n",
        "x_train = x_train.reshape((x_train.shape[0], 28,28,1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0],28,28,1)).astype('float32') / 255\n",
        "\n",
        "#one hot encoding the lables\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suzRn9Ig0nVF",
        "outputId": "ae3a7e17-49e0-478e-8486-4af0542cf0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.Conv2D(18, (3, 3), activation='relu', strides=(2,2)),\n",
        "        # layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(18, (3, 3), activation='relu', strides=(2,2)),\n",
        "        layers.Conv2D(20, (3, 3), activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        # layers.Flatten(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "print(model.count_params())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Fgl-sOIutgi2",
        "outputId": "4bf1a787-2996-4e2c-e2d4-a0fc3b0a4eaf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m18\u001b[0m)          │           \u001b[38;5;34m2,610\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m)            │           \u001b[38;5;34m2,934\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m20\u001b[0m)            │           \u001b[38;5;34m3,260\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,610</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,934</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,260</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0, 1]\n",
        "x_train = x_train[..., tf.newaxis]  # Add channel dimension\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Split into training and validation sets\n",
        "x_train, x_val = x_train[:50000], x_train[50000:]\n",
        "y_train, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# Define the CNN model\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.Conv2D(18, (3, 3), activation='relu', strides=(2,2)),\n",
        "        # layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(18, (3, 3), activation='relu', strides=(2,2)),\n",
        "        layers.Conv2D(20, (3, 3), activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        # layers.Flatten(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "# Check the parameter count\n",
        "assert model.count_params() < 10000, f\"Model has {model.count_params()} parameters, exceeds limit.\"\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training with early stopping\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=64,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n9Q34GsMY8Av",
        "outputId": "6a543740-13a7-4246-c166-6de960b46d26"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m18\u001b[0m)          │           \u001b[38;5;34m2,610\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m18\u001b[0m)            │           \u001b[38;5;34m2,934\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m20\u001b[0m)            │           \u001b[38;5;34m3,260\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,610</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,934</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,260</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6151 - loss: 1.1281 - val_accuracy: 0.9298 - val_loss: 0.2445\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2433 - val_accuracy: 0.9538 - val_loss: 0.1539\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1825 - val_accuracy: 0.9619 - val_loss: 0.1349\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.1377 - val_accuracy: 0.9593 - val_loss: 0.1336\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1234 - val_accuracy: 0.9598 - val_loss: 0.1259\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.1073 - val_accuracy: 0.9724 - val_loss: 0.0913\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0953 - val_accuracy: 0.9769 - val_loss: 0.0836\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0820 - val_accuracy: 0.9776 - val_loss: 0.0771\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0770 - val_accuracy: 0.9783 - val_loss: 0.0771\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0705 - val_accuracy: 0.9792 - val_loss: 0.0724\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0626 - val_accuracy: 0.9812 - val_loss: 0.0619\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0624 - val_accuracy: 0.9781 - val_loss: 0.0741\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.0559 - val_accuracy: 0.9822 - val_loss: 0.0604\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0505 - val_accuracy: 0.9835 - val_loss: 0.0531\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0478 - val_accuracy: 0.9825 - val_loss: 0.0590\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0497 - val_accuracy: 0.9800 - val_loss: 0.0649\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0425 - val_accuracy: 0.9834 - val_loss: 0.0551\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0418 - val_accuracy: 0.9818 - val_loss: 0.0565\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0394 - val_accuracy: 0.9827 - val_loss: 0.0592\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9776 - loss: 0.0702\n",
            "Test Accuracy: 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "\n",
        "print(train_dataset.data.shape[1:])\n",
        "print(train_loader.dataset.data.shape[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45TbBSk9kLT",
        "outputId": "c43856ef-1091-4939-a77d-532f9adba947"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.00MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "torch.Size([28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-oNkjOy0nY-",
        "outputId": "4e86cc89-a90c-45a1-8636-dbf6dfc1b670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 9812\n",
            "Epoch [1/30], Step [450/938], Loss: 0.3604\n",
            "Epoch [1/30], Step [900/938], Loss: 0.1633\n",
            "Accuracy on the test images: 92.62%\n",
            "Epoch [2/30], Step [450/938], Loss: 0.0773\n",
            "Epoch [2/30], Step [900/938], Loss: 0.1496\n",
            "Accuracy on the test images: 95.21%\n",
            "Epoch [3/30], Step [450/938], Loss: 0.2196\n",
            "Epoch [3/30], Step [900/938], Loss: 0.0953\n",
            "Accuracy on the test images: 96.29%\n",
            "Epoch [4/30], Step [450/938], Loss: 0.0309\n",
            "Epoch [4/30], Step [900/938], Loss: 0.2427\n",
            "Accuracy on the test images: 96.71%\n",
            "Epoch [5/30], Step [450/938], Loss: 0.0773\n",
            "Epoch [5/30], Step [900/938], Loss: 0.0249\n",
            "Accuracy on the test images: 96.94%\n",
            "Epoch [6/30], Step [450/938], Loss: 0.0456\n",
            "Epoch [6/30], Step [900/938], Loss: 0.0599\n",
            "Accuracy on the test images: 97.07%\n",
            "Epoch [7/30], Step [450/938], Loss: 0.0251\n",
            "Epoch [7/30], Step [900/938], Loss: 0.0940\n",
            "Accuracy on the test images: 97.89%\n",
            "Epoch [8/30], Step [450/938], Loss: 0.0417\n",
            "Epoch [8/30], Step [900/938], Loss: 0.1051\n",
            "Accuracy on the test images: 97.56%\n",
            "Epoch [9/30], Step [450/938], Loss: 0.0062\n",
            "Epoch [9/30], Step [900/938], Loss: 0.0025\n",
            "Accuracy on the test images: 97.84%\n",
            "Epoch [10/30], Step [450/938], Loss: 0.1373\n",
            "Epoch [10/30], Step [900/938], Loss: 0.0067\n",
            "Accuracy on the test images: 97.98%\n",
            "Epoch [11/30], Step [450/938], Loss: 0.0275\n",
            "Epoch [11/30], Step [900/938], Loss: 0.0648\n",
            "Accuracy on the test images: 98.21%\n",
            "Epoch [12/30], Step [450/938], Loss: 0.0822\n",
            "Epoch [12/30], Step [900/938], Loss: 0.0977\n",
            "Accuracy on the test images: 98.17%\n",
            "Epoch [13/30], Step [450/938], Loss: 0.0105\n",
            "Epoch [13/30], Step [900/938], Loss: 0.0136\n",
            "Accuracy on the test images: 97.92%\n",
            "Epoch [14/30], Step [450/938], Loss: 0.0140\n",
            "Epoch [14/30], Step [900/938], Loss: 0.0838\n",
            "Accuracy on the test images: 97.81%\n",
            "Epoch [15/30], Step [450/938], Loss: 0.0212\n",
            "Epoch [15/30], Step [900/938], Loss: 0.0035\n",
            "Accuracy on the test images: 98.08%\n",
            "Epoch [16/30], Step [450/938], Loss: 0.0333\n",
            "Epoch [16/30], Step [900/938], Loss: 0.0470\n",
            "Accuracy on the test images: 98.30%\n",
            "Epoch [17/30], Step [450/938], Loss: 0.0284\n",
            "Epoch [17/30], Step [900/938], Loss: 0.0026\n",
            "Accuracy on the test images: 98.21%\n",
            "Epoch [18/30], Step [450/938], Loss: 0.0018\n",
            "Epoch [18/30], Step [900/938], Loss: 0.0162\n",
            "Accuracy on the test images: 97.64%\n",
            "Epoch [19/30], Step [450/938], Loss: 0.0059\n",
            "Epoch [19/30], Step [900/938], Loss: 0.0045\n",
            "Accuracy on the test images: 98.39%\n",
            "Epoch [20/30], Step [450/938], Loss: 0.0109\n",
            "Epoch [20/30], Step [900/938], Loss: 0.0064\n",
            "Accuracy on the test images: 98.28%\n",
            "Epoch [21/30], Step [450/938], Loss: 0.0102\n",
            "Epoch [21/30], Step [900/938], Loss: 0.0132\n",
            "Accuracy on the test images: 98.21%\n",
            "Epoch [22/30], Step [450/938], Loss: 0.0209\n",
            "Epoch [22/30], Step [900/938], Loss: 0.0172\n",
            "Accuracy on the test images: 98.14%\n",
            "Epoch [23/30], Step [450/938], Loss: 0.0098\n",
            "Epoch [23/30], Step [900/938], Loss: 0.0258\n",
            "Accuracy on the test images: 98.31%\n",
            "Epoch [24/30], Step [450/938], Loss: 0.0048\n",
            "Epoch [24/30], Step [900/938], Loss: 0.0311\n",
            "Accuracy on the test images: 98.60%\n",
            "Epoch [25/30], Step [450/938], Loss: 0.0204\n",
            "Epoch [25/30], Step [900/938], Loss: 0.0084\n",
            "Accuracy on the test images: 98.60%\n",
            "Epoch [26/30], Step [450/938], Loss: 0.0069\n",
            "Epoch [26/30], Step [900/938], Loss: 0.0567\n",
            "Accuracy on the test images: 98.02%\n",
            "Epoch [27/30], Step [450/938], Loss: 0.0120\n",
            "Epoch [27/30], Step [900/938], Loss: 0.0020\n",
            "Accuracy on the test images: 98.49%\n",
            "Epoch [28/30], Step [450/938], Loss: 0.0012\n",
            "Epoch [28/30], Step [900/938], Loss: 0.0136\n",
            "Accuracy on the test images: 98.44%\n",
            "Epoch [29/30], Step [450/938], Loss: 0.0098\n",
            "Epoch [29/30], Step [900/938], Loss: 0.0026\n",
            "Accuracy on the test images: 98.48%\n",
            "Epoch [30/30], Step [450/938], Loss: 0.0196\n",
            "Epoch [30/30], Step [900/938], Loss: 0.0015\n",
            "Accuracy on the test images: 98.26%\n",
            "Training time: 502.77s\n"
          ]
        }
      ],
      "source": [
        "class PytorchModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PytorchModel, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),  # Input: 28x28 -> Output: 28x28 # Added padding=1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(8, 12, kernel_size=3, stride=2, padding=1),  # Input: 28x28 -> Output: 14x14 # Added padding=1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(12, 16, kernel_size=3, stride=2, padding=1),  # Input: 14x14 -> Output: 7x7 # Added padding=1\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 20, kernel_size=3, stride=2, padding=1),  # Input: 7x7 -> Output: 4x4 # Added padding=1, adjusted stride to 2\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(20, 22, kernel_size=3, stride=1, padding=1),  # Input: 4x4 -> Output: 4x4  # Added padding=1\n",
        "        nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling: Output: 20x1x1\n",
        "        nn.Flatten(),  # Flatten the output for Dense layer\n",
        "        nn.Linear(22, 10),  # Fully connected layer with 10 outputs\n",
        "    )\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "# Check parameter count\n",
        "model = PytorchModel()\n",
        "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable parameters: {param_count}\")\n",
        "\n",
        "# Ensure parameters are under 10,000\n",
        "assert param_count < 10000, \"Model exceeds parameter limit!\"\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 30\n",
        "start_time = time()\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 450 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Accuracy on the test images: {accuracy:.2f}%')\n",
        "\n",
        "end_time = time()\n",
        "print(f\"Training time: {(end_time - start_time):.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4Pls_waTut6"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}